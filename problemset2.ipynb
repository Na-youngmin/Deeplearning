{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f36a2146",
   "metadata": {},
   "source": [
    "이름: 나영민\n",
    "\n",
    "학번: 20183217"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "069c04dd",
   "metadata": {},
   "source": [
    "# Neural networks with PyTorch\n",
    "\n",
    "Pytorch의 `nn.module`을 활용하여 만드는 유용한 방법을 학습합니다.\n",
    "\n",
    "<div style=\"text-align:center\"><img src='https://drive.google.com/uc?export=download&id=1J2SeiPpVJs1-ML2BdLrcxkGGmHpRxIVE' width=\"250\" height=\"200\"> \n",
    "\n",
    "### Lego block coding! </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2fd06918",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x10b2ddab0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from collections import OrderedDict\n",
    "\n",
    "torch.manual_seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d605a354",
   "metadata": {},
   "source": [
    "`nn.Linear`: $Z^{[\\ell]} = A^{[\\ell-1]}W^T+b$\n",
    "연산.\n",
    "\n",
    "해당 layer의 \n",
    "\n",
    "- 입력 차원 `n_input=30`\n",
    "- 출력 차원 `n_output=60`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0fe1c09d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of nn.linear\n",
    "linear_layer1 = nn.Linear(30, 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1e4a14fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([60, 60])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = torch.randn(60, 30)\n",
    "linear_layer1(A).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82bcbcbf",
   "metadata": {},
   "source": [
    "How to get the weights and bias of each `nn.Linear`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e636fd8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of weights\n",
    "linear_layer1.weight.data = torch.ones_like(linear_layer1.weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "214864da-24f2-454f-8f90-3db57cfefa91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[1., 1., 1.,  ..., 1., 1., 1.],\n",
       "        [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "        [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "        ...,\n",
       "        [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "        [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "        [1., 1., 1.,  ..., 1., 1., 1.]], requires_grad=True)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_layer1.weight "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94a96b2d",
   "metadata": {},
   "source": [
    "### NN example\n",
    "\n",
    "- input units: 20\n",
    "- hidden layer: 30, 40\n",
    "- output units: 3\n",
    "- activation function: ReLU\n",
    "- output layer: No activation\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9c09e678",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple NN construction\n",
    "\n",
    "class FCN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.lin1 = nn.Linear(20, 30)\n",
    "        self.lin2 = nn.Linear(30, 40)\n",
    "        self.lin3 = nn.Linear(40, 3)\n",
    "        self.relu = nn.ReLU(True)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.lin1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.lin2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.lin3(x)\n",
    "        return x\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "88009d27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.1835,  0.0993, -0.2714],\n",
       "        [ 0.3332,  0.2873, -0.3591],\n",
       "        [ 0.3309,  0.2476, -0.3577],\n",
       "        [ 0.1238,  0.2104, -0.2191],\n",
       "        [ 0.2073,  0.1916, -0.2385],\n",
       "        [ 0.2006,  0.1463, -0.2508],\n",
       "        [ 0.2636,  0.2812, -0.4325],\n",
       "        [ 0.2828,  0.1841, -0.2341],\n",
       "        [ 0.1539,  0.2094, -0.2452],\n",
       "        [ 0.0792,  0.1489, -0.1712],\n",
       "        [ 0.2080,  0.2306, -0.3681],\n",
       "        [ 0.2313,  0.1119, -0.3857],\n",
       "        [ 0.1765,  0.1590, -0.1997],\n",
       "        [ 0.3639,  0.1522, -0.2656],\n",
       "        [ 0.2642,  0.1714, -0.2678],\n",
       "        [ 0.2187,  0.1344, -0.1754],\n",
       "        [ 0.1186,  0.1411, -0.1231],\n",
       "        [ 0.2653,  0.1869, -0.3321],\n",
       "        [ 0.1993,  0.1813, -0.2347],\n",
       "        [ 0.2322,  0.2906, -0.4095],\n",
       "        [ 0.2172,  0.0992, -0.2397],\n",
       "        [ 0.2361,  0.3409, -0.4224],\n",
       "        [ 0.3504,  0.3091, -0.4316],\n",
       "        [ 0.1988,  0.0777, -0.2611],\n",
       "        [ 0.2096,  0.2100, -0.2556],\n",
       "        [ 0.1307,  0.0951, -0.1367],\n",
       "        [ 0.2979,  0.2679, -0.3730],\n",
       "        [ 0.2133,  0.2414, -0.2829],\n",
       "        [ 0.1636,  0.1654, -0.0887],\n",
       "        [ 0.2436,  0.1755, -0.3518],\n",
       "        [ 0.2064,  0.1682, -0.3664],\n",
       "        [ 0.2422,  0.0596, -0.1905],\n",
       "        [ 0.1911,  0.2636, -0.2607],\n",
       "        [ 0.2342,  0.2275, -0.2518],\n",
       "        [ 0.2693,  0.1609, -0.2802],\n",
       "        [ 0.2704,  0.2055, -0.2023],\n",
       "        [ 0.1757,  0.1741, -0.1520],\n",
       "        [ 0.1951,  0.1871, -0.1441],\n",
       "        [ 0.2212,  0.2476, -0.3055],\n",
       "        [ 0.2672,  0.1323, -0.2706],\n",
       "        [ 0.0381,  0.2006, -0.1413],\n",
       "        [ 0.2312,  0.3665, -0.3781],\n",
       "        [ 0.1677,  0.1094, -0.1955],\n",
       "        [ 0.1356,  0.2823, -0.2503],\n",
       "        [ 0.2918,  0.2095, -0.3051],\n",
       "        [ 0.2373,  0.1873, -0.2471],\n",
       "        [ 0.2935,  0.3839, -0.3958],\n",
       "        [ 0.1530,  0.2266, -0.2578],\n",
       "        [ 0.2146,  0.1485, -0.2296],\n",
       "        [ 0.1553,  0.0786, -0.2362],\n",
       "        [ 0.1568,  0.1705, -0.2190],\n",
       "        [ 0.1667,  0.3617, -0.3907],\n",
       "        [ 0.1705,  0.2302, -0.3197],\n",
       "        [ 0.2123,  0.1395, -0.3335],\n",
       "        [ 0.2344,  0.1383, -0.3280],\n",
       "        [ 0.1975,  0.1594, -0.3217],\n",
       "        [ 0.1653,  0.1123, -0.3274],\n",
       "        [ 0.2173,  0.1246, -0.3356],\n",
       "        [ 0.1575,  0.1398, -0.1207],\n",
       "        [ 0.2454,  0.1683, -0.2477]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtrain = torch.randn(60, 20)\n",
    "\n",
    "model = FCN()\n",
    "model(Xtrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f646b76f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FCN(\n",
       "  (lin1): Linear(in_features=20, out_features=30, bias=True)\n",
       "  (lin2): Linear(in_features=30, out_features=40, bias=True)\n",
       "  (lin3): Linear(in_features=40, out_features=3, bias=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5a24fa36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of parameters() in models\n",
    "# param_iterator = model.parameters()\n",
    "\n",
    "# for param in param_iterator:\n",
    "#     print(param)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "929f4cb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nn.Sequential() example\n",
    "\n",
    "class FCN_seq(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.fc = nn.Sequential(nn.Linear(20, 30),\n",
    "                      nn.ReLU(True),\n",
    "                      nn.Linear(30, 40),\n",
    "                      nn.ReLU(True),\n",
    "                      nn.Linear(40, 3)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.fc(x)\n",
    "        \n",
    "        \n",
    "        \n",
    "# self.lin1 = nn.Linear(20, 30)\n",
    "# self.lin2 = nn.Linear(30, 40)\n",
    "# self.lin3 = nn.Linear(40, 3)\n",
    "# self.relu = nn.ReLU(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "653f0bb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FCN_seq(\n",
       "  (fc): Sequential(\n",
       "    (0): Linear(in_features=20, out_features=30, bias=True)\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Linear(in_features=30, out_features=40, bias=True)\n",
       "    (3): ReLU(inplace=True)\n",
       "    (4): Linear(in_features=40, out_features=3, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_seq = FCN_seq()\n",
    "Xtrain.shape\n",
    "model_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f0db292b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear(in_features=20, out_features=30, bias=True)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_seq.fc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9a16dc4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FCN_seq_v2(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "\n",
    "        \n",
    "        temp = self.fcn_block(20, 30)+self.fcn_block(30, 40)+[nn.Linear(40,1)]\n",
    "        self.fc = nn.Sequential(*temp)\n",
    "        \n",
    "        \n",
    "    def fcn_block(self, in_dim, out_dim):\n",
    "        return [nn.Linear(in_dim, out_dim),\n",
    "                             nn.ReLU(True)]\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.fc(x)\n",
    "        \n",
    "        \n",
    "        \n",
    "# self.lin1 = nn.Linear(20, 30)\n",
    "# self.lin2 = nn.Linear(30, 40)\n",
    "# self.lin3 = nn.Linear(40, 3)\n",
    "# self.relu = nn.ReLU(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0ac30117",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FCN_seq_v2(\n",
       "  (fc): Sequential(\n",
       "    (0): Linear(in_features=20, out_features=30, bias=True)\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Linear(in_features=30, out_features=40, bias=True)\n",
       "    (3): ReLU(inplace=True)\n",
       "    (4): Linear(in_features=40, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_seq_v2 = FCN_seq_v2()\n",
    "model_seq_v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "514cccdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FCN_final(nn.Module):\n",
    "    def __init__(self, in_dim, hlayer, out_dim):\n",
    "        super().__init__()\n",
    "        \n",
    "        l_list = self.fcn_block(in_dim, hlayer[0])\n",
    "        \n",
    "        for l1, l2 in zip(hlayer[:-1], hlayer[1:]):\n",
    "            l_list = l_list + self.fcn_block(l1, l2)\n",
    "        \n",
    "        l_list = l_list + [nn.Linear(hlayer[-1], out_dim)]\n",
    "        \n",
    "        self.fc = nn.Sequential(*l_list)\n",
    "        \n",
    "        \n",
    "    def fcn_block(self, in_dim, out_dim):\n",
    "        return [nn.Linear(in_dim, out_dim),\n",
    "                             nn.ReLU(True)]\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.fc(x)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "05a543cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "hlayer = [30, 40]\n",
    "in_dim = 20\n",
    "out_dim= 3\n",
    "\n",
    "myfcn_final = FCN_final(in_dim, hlayer, out_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d545559c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FCN_final(\n",
       "  (fc): Sequential(\n",
       "    (0): Linear(in_features=20, out_features=30, bias=True)\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Linear(in_features=30, out_features=40, bias=True)\n",
       "    (3): ReLU(inplace=True)\n",
       "    (4): Linear(in_features=40, out_features=3, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myfcn_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d419c48e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ordered dict example\n",
    "# nn.Sequential() example\n",
    "\n",
    "class FCN_seq_ordered_dic(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.fc = nn.Sequential(OrderedDict([('lin1', nn.Linear(20, 30)),\n",
    "                      ('relu1', nn.ReLU(True)),\n",
    "                      ('lin2', nn.Linear(30, 40)),\n",
    "                      ('relu2',nn.ReLU(True)),\n",
    "                      ('lin3', nn.Linear(40, 3))\n",
    "                                            ])\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.fc(x)\n",
    "        \n",
    "        \n",
    "        \n",
    "# self.lin1 = nn.Linear(20, 30)\n",
    "# self.lin2 = nn.Linear(30, 40)\n",
    "# self.lin3 = nn.Linear(40, 3)\n",
    "# self.relu = nn.ReLU(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a876e852",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ModuleList(), ModuleDict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "eb4c2ad8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('lin1.weight',\n",
       "              tensor([[ 1.1542e-01, -1.5343e-01, -1.4473e-01,  6.0137e-02,  3.4798e-02,\n",
       "                       -1.9658e-01, -1.6290e-01, -1.7801e-01,  1.7759e-01,  1.4619e-01,\n",
       "                       -1.1770e-01,  3.3738e-02, -5.1431e-02,  1.9439e-01, -2.0253e-01,\n",
       "                       -1.6313e-01, -1.8617e-01,  1.3013e-01, -1.1178e-01,  1.3318e-01],\n",
       "                      [ 7.5586e-02, -1.0930e-01, -6.0237e-02, -9.0490e-02,  9.8650e-02,\n",
       "                       -8.9674e-02,  7.5885e-02,  1.5974e-02, -1.7857e-01, -1.4056e-01,\n",
       "                       -1.5504e-01,  1.1717e-01,  4.8451e-02, -5.6224e-03, -1.3314e-01,\n",
       "                       -2.2155e-01, -7.9131e-02, -1.7114e-01, -2.2241e-01, -2.1327e-01],\n",
       "                      [-1.4606e-01, -2.1738e-01,  6.9704e-02,  8.3668e-02,  9.0129e-02,\n",
       "                       -2.2260e-01,  1.3827e-01,  4.3595e-02,  1.1434e-01, -5.4957e-02,\n",
       "                        1.0738e-01, -2.1207e-01,  7.6162e-02,  1.7731e-01,  9.3997e-02,\n",
       "                       -2.1077e-01, -6.2772e-02, -2.7768e-02,  1.1716e-01, -8.4613e-02],\n",
       "                      [ 3.2161e-02, -7.8497e-02, -3.5522e-02, -4.4512e-03, -1.2840e-01,\n",
       "                       -1.5520e-01,  1.8460e-01,  1.8787e-01, -6.7696e-03,  1.9355e-01,\n",
       "                        1.7231e-01, -1.4085e-01, -8.8852e-02, -1.5358e-01,  7.2294e-02,\n",
       "                        5.6551e-03, -3.0665e-02,  1.6602e-01, -8.7401e-02, -1.2238e-01],\n",
       "                      [-1.5896e-01, -1.1376e-01,  2.1552e-01, -1.0872e-01, -6.1526e-02,\n",
       "                        1.0078e-01, -1.7174e-01, -1.3572e-01,  1.6458e-01, -8.5763e-02,\n",
       "                       -1.1603e-01, -2.8930e-02, -3.1862e-02,  4.0865e-02,  8.1979e-02,\n",
       "                       -1.7241e-01,  2.0321e-01, -2.1259e-01,  7.5732e-02, -6.3092e-02],\n",
       "                      [-9.4428e-02,  2.0917e-01, -2.1548e-01,  1.5271e-02,  1.4328e-01,\n",
       "                        1.9990e-01, -1.8904e-01,  2.6941e-02,  2.2123e-01, -2.1903e-01,\n",
       "                        5.4616e-02, -1.4011e-01,  3.6300e-02, -2.0227e-01,  1.1002e-01,\n",
       "                       -4.9605e-02,  1.3364e-01, -3.3625e-03, -3.1873e-02, -5.4288e-02],\n",
       "                      [-2.0474e-01, -9.4979e-02,  7.4261e-03, -1.7299e-01,  1.9624e-01,\n",
       "                       -1.4543e-01, -8.7115e-02, -2.9903e-02, -1.8114e-01, -1.7667e-03,\n",
       "                       -1.0768e-01, -1.8717e-01,  5.4847e-03,  1.9796e-01,  5.5063e-02,\n",
       "                        1.8443e-01, -2.1867e-03, -7.8048e-02,  1.8022e-01, -1.1907e-01],\n",
       "                      [-2.0686e-01,  4.8939e-02,  1.1144e-01, -1.3366e-01,  7.8702e-02,\n",
       "                       -7.9332e-02, -2.7131e-02, -4.9511e-02, -4.7828e-02, -1.8194e-01,\n",
       "                        5.4802e-02, -5.8818e-02,  1.7098e-01,  3.7323e-02, -1.8287e-01,\n",
       "                       -1.7011e-01, -1.1654e-01,  1.0708e-01, -1.4437e-01, -1.0229e-01],\n",
       "                      [ 4.0596e-02, -1.5503e-01, -1.1011e-01,  2.0276e-01, -1.1822e-01,\n",
       "                       -7.4499e-02,  1.5992e-01,  5.0107e-02,  1.7551e-01, -1.9700e-01,\n",
       "                        1.1177e-01, -3.4202e-02, -1.4325e-01, -9.5770e-02, -2.1629e-01,\n",
       "                        1.5469e-01, -4.2906e-02, -2.1926e-01,  1.9123e-01,  1.4483e-01],\n",
       "                      [ 9.2458e-02,  2.1885e-01,  2.0193e-01,  2.0897e-01,  2.0025e-01,\n",
       "                        1.8172e-01,  5.8538e-02, -1.8726e-02,  8.5036e-03, -9.2926e-02,\n",
       "                        1.0506e-01,  6.4780e-03,  5.2755e-02, -1.4404e-01, -8.4194e-02,\n",
       "                        1.6764e-01,  2.1748e-02,  7.7165e-02, -1.9521e-01, -9.5754e-02],\n",
       "                      [-5.6909e-03, -2.3464e-02,  1.4274e-01, -6.7481e-02,  1.8662e-01,\n",
       "                       -4.3247e-02,  8.6972e-02, -1.5743e-01,  3.7954e-02, -2.1800e-01,\n",
       "                       -1.9185e-01, -1.4311e-01,  6.2600e-02,  1.7331e-02,  2.1642e-02,\n",
       "                       -2.4460e-02,  1.8789e-01,  2.1905e-01,  9.4963e-02,  1.7782e-01],\n",
       "                      [-1.1051e-02, -8.2205e-02,  4.3471e-02,  1.4703e-01, -3.4559e-02,\n",
       "                       -1.7169e-01,  7.3843e-02, -5.7001e-02, -1.0764e-01,  1.4124e-01,\n",
       "                       -7.5897e-03, -1.2782e-01, -1.3380e-01,  2.1058e-01,  1.4544e-01,\n",
       "                       -1.6034e-01,  1.0689e-04, -4.8377e-03,  1.0659e-01, -1.9151e-01],\n",
       "                      [ 3.3233e-03,  7.4504e-02,  1.1379e-01,  2.3381e-02, -1.1084e-01,\n",
       "                       -2.1467e-01,  1.2086e-01,  2.0414e-01, -6.7511e-02, -1.9983e-01,\n",
       "                        6.5424e-02, -1.5677e-01, -1.4610e-01,  6.0952e-02, -2.1234e-02,\n",
       "                       -1.5210e-02,  2.0056e-01, -3.9221e-02,  1.3611e-01, -6.9592e-02],\n",
       "                      [ 1.6639e-01,  6.8216e-02,  1.9926e-01,  7.7989e-02, -7.9205e-02,\n",
       "                        9.7460e-02,  1.9051e-01,  4.2381e-02,  1.0309e-01, -1.5731e-01,\n",
       "                        1.2116e-01, -2.1137e-01,  1.9767e-01,  9.2355e-02,  1.4715e-02,\n",
       "                       -2.0929e-01,  2.0334e-01,  1.4258e-01,  2.0614e-01,  8.7902e-02],\n",
       "                      [ 7.5306e-02, -5.7922e-02, -9.1634e-02,  8.8638e-02,  7.7548e-02,\n",
       "                       -7.2493e-03,  3.5567e-02,  7.6812e-02, -2.1608e-01, -1.9775e-01,\n",
       "                       -5.9525e-02,  1.5229e-01,  1.0909e-01, -2.1342e-01, -6.7138e-02,\n",
       "                       -2.3636e-02,  7.3442e-02,  1.8294e-01,  4.8906e-03, -1.7405e-01],\n",
       "                      [ 1.3720e-02, -8.6348e-02, -1.3666e-01,  1.2385e-01, -3.0042e-02,\n",
       "                        1.0566e-01,  1.7411e-01,  2.1976e-02,  1.2595e-01, -1.0561e-01,\n",
       "                        1.2482e-01,  8.9331e-03,  1.4859e-01,  2.1378e-01, -1.6915e-01,\n",
       "                        2.1227e-01,  1.7069e-01, -1.8013e-01,  6.5548e-02, -1.8204e-01],\n",
       "                      [ 7.2535e-02,  3.4579e-02, -2.1346e-01,  8.1173e-02, -6.1420e-02,\n",
       "                        2.2289e-01,  2.1824e-01,  7.7191e-02,  1.7626e-01,  8.0762e-02,\n",
       "                        2.1155e-01, -2.0645e-02,  5.5265e-02, -3.6936e-02, -3.9105e-03,\n",
       "                       -6.7455e-02, -8.8493e-02,  1.2935e-01,  9.5956e-02, -9.8709e-02],\n",
       "                      [-1.9707e-01,  1.0933e-01, -2.0569e-01, -9.8949e-03, -1.9240e-01,\n",
       "                        1.8723e-01,  1.8208e-01, -1.8377e-01, -2.0789e-01, -1.3221e-01,\n",
       "                        6.1702e-02, -1.1182e-01, -5.3251e-02, -5.6680e-02,  4.1017e-02,\n",
       "                       -1.0577e-01,  1.0170e-01, -1.6001e-01, -1.9904e-02,  1.8743e-01],\n",
       "                      [-1.2347e-01,  1.7156e-01,  1.1638e-01, -7.2229e-02,  7.7539e-02,\n",
       "                       -1.5106e-01,  1.7996e-02,  6.3339e-02,  1.9341e-01, -1.2513e-01,\n",
       "                       -1.2717e-01, -1.1160e-01, -2.1783e-01,  4.5219e-02, -1.8509e-01,\n",
       "                       -6.0026e-02, -9.9769e-02,  1.2502e-02,  6.7831e-02, -1.6249e-01],\n",
       "                      [-6.6012e-02, -2.1497e-02, -1.2926e-01,  5.1656e-02,  8.2778e-02,\n",
       "                       -1.5936e-01,  1.7583e-01,  1.5889e-01, -6.7177e-02,  3.3271e-02,\n",
       "                        2.7226e-02, -3.0851e-02, -1.5007e-01,  1.8426e-01,  1.1004e-01,\n",
       "                       -1.8686e-01, -1.7330e-01,  2.1264e-01,  3.5689e-02, -5.1373e-02],\n",
       "                      [ 1.5155e-01,  6.4238e-02,  8.0268e-02,  1.7740e-01, -1.7452e-02,\n",
       "                        2.1307e-01, -1.5707e-01, -1.3606e-01,  3.7888e-02, -2.7147e-02,\n",
       "                        1.2760e-01, -6.0805e-02,  3.5162e-02, -4.6463e-02,  1.6787e-01,\n",
       "                       -1.4667e-02,  3.4322e-03,  1.6381e-01,  2.1739e-01,  2.1396e-01],\n",
       "                      [-2.1863e-01, -1.2635e-01, -4.8556e-02, -4.6162e-02,  1.2934e-01,\n",
       "                        1.0099e-01, -1.8392e-02,  5.2972e-03,  4.7909e-02,  1.9276e-01,\n",
       "                        1.1588e-01, -1.1279e-01, -1.1455e-01,  7.0715e-02, -2.2617e-02,\n",
       "                       -1.4345e-01, -2.1642e-01,  3.2030e-02, -6.5298e-02, -1.3010e-01],\n",
       "                      [ 4.2063e-02,  2.1774e-01,  1.8572e-01,  1.2749e-01, -1.6864e-01,\n",
       "                        1.2762e-01,  1.1565e-01,  7.4605e-02, -5.5701e-02, -3.8937e-03,\n",
       "                       -1.2128e-01, -5.0369e-02, -3.6809e-02, -3.1675e-02, -2.2253e-01,\n",
       "                        7.8886e-02, -1.8295e-01, -1.6722e-01,  9.0867e-02, -1.8304e-01],\n",
       "                      [ 2.1332e-01,  2.1411e-01, -7.1058e-02, -3.8537e-02, -1.7107e-01,\n",
       "                        1.3824e-02,  4.0883e-02, -1.2266e-01,  7.0119e-02, -8.6055e-03,\n",
       "                       -6.5915e-02, -7.7361e-04, -2.1675e-01, -1.5752e-01,  2.9598e-02,\n",
       "                        2.1594e-01, -1.3254e-01,  1.4335e-01,  2.0464e-02, -9.6203e-02],\n",
       "                      [ 2.4499e-04,  1.0720e-01,  2.6603e-02,  1.9794e-01, -4.2319e-02,\n",
       "                       -1.4932e-01,  2.0206e-01, -6.3862e-02,  1.4188e-01,  1.4749e-01,\n",
       "                        3.9602e-02, -1.8352e-01, -2.1952e-01,  1.0615e-01,  5.4670e-02,\n",
       "                        1.3011e-01, -1.9709e-01, -3.0807e-02,  1.9320e-01,  1.1748e-01],\n",
       "                      [ 1.8582e-01,  1.7556e-01, -5.4866e-02, -1.5227e-01, -1.3333e-01,\n",
       "                        7.5943e-02, -8.8758e-02,  8.8681e-04,  3.5684e-02,  1.3881e-01,\n",
       "                        1.2471e-01,  1.2762e-01,  9.0880e-03,  1.2624e-01, -1.0468e-01,\n",
       "                       -8.9498e-02, -3.5404e-02, -1.2985e-01,  1.9946e-01, -3.4264e-02],\n",
       "                      [ 6.5008e-02, -6.9521e-03, -3.0583e-03, -1.1918e-01, -1.6417e-02,\n",
       "                       -2.0002e-01, -1.0693e-01,  1.7208e-01, -2.0973e-01,  3.6797e-02,\n",
       "                        3.5623e-02, -2.1402e-01,  4.3674e-02,  1.0382e-01,  1.6195e-01,\n",
       "                        4.1854e-02,  1.7479e-01,  8.4166e-03,  8.5199e-02,  6.6011e-02],\n",
       "                      [-1.6487e-01, -4.9085e-02, -1.5747e-01,  1.7374e-01,  1.0667e-01,\n",
       "                       -9.4833e-02, -4.0919e-02,  5.9693e-02, -1.9497e-01,  6.3140e-03,\n",
       "                        1.0666e-01,  2.8018e-02, -2.0574e-02,  1.4376e-01,  9.7266e-02,\n",
       "                       -1.9879e-01,  1.3160e-01, -1.7636e-01,  1.2561e-01,  1.8829e-01],\n",
       "                      [ 2.0608e-02, -7.5573e-02, -1.1550e-01, -9.9290e-02, -4.1218e-02,\n",
       "                       -9.2703e-02,  2.2198e-01, -9.6452e-02,  9.2839e-02, -2.0736e-01,\n",
       "                        1.1334e-01,  1.9027e-01, -1.6030e-01, -5.7052e-02,  5.3294e-02,\n",
       "                       -2.1404e-01, -1.4148e-01,  7.7767e-02,  2.1056e-01, -6.6801e-02],\n",
       "                      [-2.0364e-03, -2.1586e-01, -2.1463e-01,  1.9447e-01,  1.8975e-01,\n",
       "                       -6.8148e-02, -8.8418e-02, -1.4475e-02,  1.0375e-01, -2.1609e-01,\n",
       "                       -1.2386e-01, -7.3717e-02, -9.7327e-02, -5.9071e-03,  1.6310e-01,\n",
       "                        4.8822e-02, -2.0236e-01,  2.0681e-01,  1.8005e-01,  7.0404e-02]])),\n",
       "             ('lin1.bias',\n",
       "              tensor([ 0.1095,  0.0836,  0.1833, -0.2151, -0.1392, -0.0284, -0.0425, -0.1485,\n",
       "                      -0.2144, -0.1708, -0.0347,  0.1898,  0.1482,  0.0645, -0.1373, -0.0900,\n",
       "                       0.0215, -0.2073, -0.0102,  0.0455,  0.2022, -0.0587,  0.2195,  0.0169,\n",
       "                      -0.1551,  0.2113,  0.1939, -0.1767, -0.1297,  0.1069])),\n",
       "             ('lin2.weight',\n",
       "              tensor([[-0.1123,  0.1241, -0.0871,  ...,  0.1139,  0.0594, -0.0519],\n",
       "                      [ 0.0592,  0.1546,  0.1343,  ..., -0.1459,  0.0904,  0.0278],\n",
       "                      [ 0.0019, -0.0117,  0.1542,  ...,  0.1597,  0.1546, -0.1344],\n",
       "                      ...,\n",
       "                      [-0.1407, -0.1203, -0.1250,  ...,  0.0393,  0.1626, -0.0863],\n",
       "                      [ 0.0852, -0.0249, -0.1033,  ...,  0.0305, -0.1305,  0.0260],\n",
       "                      [ 0.1099,  0.1278, -0.0302,  ..., -0.0994,  0.0479,  0.0188]])),\n",
       "             ('lin2.bias',\n",
       "              tensor([ 0.0129, -0.0992,  0.1278,  0.0262,  0.0678,  0.0213, -0.0908, -0.0686,\n",
       "                       0.1215, -0.1595, -0.0631, -0.1671, -0.1091,  0.0245, -0.0416,  0.0608,\n",
       "                       0.1391,  0.0384,  0.1734, -0.0005,  0.1761,  0.0295, -0.0047,  0.0510,\n",
       "                      -0.1440,  0.1489,  0.1671, -0.1606, -0.1087,  0.1443,  0.0459, -0.0660,\n",
       "                      -0.0910, -0.0418, -0.0344,  0.1684, -0.1110,  0.0257,  0.0517, -0.0906])),\n",
       "             ('lin3.weight',\n",
       "              tensor([[-0.0099, -0.0286,  0.1206,  0.1131, -0.0076, -0.0810, -0.0908, -0.0673,\n",
       "                        0.1372,  0.1285,  0.0314, -0.1473,  0.0505, -0.0294,  0.0884,  0.0822,\n",
       "                        0.1326,  0.0115,  0.0121,  0.0011,  0.1092,  0.1194,  0.0745, -0.0316,\n",
       "                       -0.0459,  0.1465, -0.0818,  0.0272,  0.0497,  0.0819, -0.0959, -0.0305,\n",
       "                       -0.0046, -0.0144, -0.1357,  0.0682, -0.1209, -0.0399,  0.0485,  0.1243],\n",
       "                      [-0.0275, -0.0875, -0.0705, -0.0015, -0.0864,  0.0391,  0.0715,  0.1492,\n",
       "                        0.1330, -0.0323,  0.0672,  0.0207,  0.0750, -0.0719,  0.1485,  0.0011,\n",
       "                        0.1001,  0.1173, -0.0335,  0.1212, -0.0409,  0.0787, -0.0245, -0.1250,\n",
       "                       -0.0403,  0.0600,  0.1263, -0.1290, -0.0918,  0.0824, -0.0808,  0.0082,\n",
       "                       -0.1103,  0.0100, -0.0765,  0.0353,  0.0623,  0.0303, -0.1243,  0.1185],\n",
       "                      [ 0.1331, -0.1418,  0.1295, -0.1363,  0.0743, -0.0093, -0.0126, -0.0770,\n",
       "                        0.1245,  0.0256, -0.0110, -0.0056,  0.1146,  0.1567, -0.0901, -0.1402,\n",
       "                       -0.1070, -0.0858, -0.1292, -0.0571, -0.0612, -0.0011,  0.0451,  0.1016,\n",
       "                       -0.1043, -0.1133, -0.0689, -0.1165,  0.0085, -0.1199, -0.0073, -0.0216,\n",
       "                       -0.1224, -0.0714,  0.0691, -0.0453, -0.1396,  0.1286, -0.0493,  0.0191]])),\n",
       "             ('lin3.bias', tensor([ 0.1272,  0.0787, -0.1278]))])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# state_dict() example\n",
    "model.state_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45c586f6",
   "metadata": {},
   "source": [
    "# Problem Setup\n",
    "\n",
    "<div style=\"text-align:center\"> <img src='https://drive.google.com/uc?export=download&id=1FRhniwGeeutBSJQRdW6GzshMfDrPz7oJ' width=\"250\" height=\"200\"> </div>\n",
    "    \n",
    "Build a Fully connected neural network with\n",
    "\n",
    "- 3 layers\n",
    "- 마지막 layer의 unit 수는 `1` \n",
    "  - 마지막 layer의 activation은 없음 (linear layer)\n",
    "- Data feature 수는 `100`\n",
    "\n",
    "- input unit 수는 data 크기를 보고 맞추세요\n",
    "- hidden layer의 unit 수는 `[80, 50]`\n",
    "  - hidden layer의 activation 함수는 ReLU\n",
    "\n",
    "- model class 명 `myFCN`\n",
    "  - instance 명 `my_model` 생성\n",
    "  - `my_model` 출력"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15d8150a-5d25-40fe-951a-416a5f022112",
   "metadata": {},
   "source": [
    "## Problem 1\n",
    "\n",
    "problem setup에서 구성한 neural network을 `nn.Sequential`을 활용하여 생성하세요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3dabeb42",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 사용할 data \n",
    "batch_size = 30\n",
    "num_feature = 100\n",
    "\n",
    "X_train = torch.randn(batch_size, num_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "dc5c673c-068b-4201-8900-3669a84d420a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([30, 100])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "82fc8c73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Problem 1 코딩 (매 줄마다 주석 필수 )\n",
    "\n",
    "class FCN_seq(nn.Module):   # nn.Module 클래스를 상속받는 FCN_seq라는 클래스를 생성\n",
    "    def __init__(self): #모델을 정의\n",
    "        super().__init__() #상위 클래스의 생성자를 호출해 실행\n",
    "        \n",
    "        #self.fc는 nn.Sequential을 사용하여 순차적으로 층을 쌓는 fully connected layer를 정의한다.\n",
    "        self.fc = nn.Sequential(nn.Linear(100, 80), # 입력값이 100이며 출력값은 80인 fully connected layer\n",
    "                      nn.ReLU(True), #액티베이션 함수 렐루를 적용\n",
    "                      nn.Linear(80, 50), #입력값이 80이며 출력값은 50인 fully connected layer\n",
    "                      nn.ReLU(True), #액티베이션 함수 렐루를 적용\n",
    "                      nn.Linear(50, 1) #입력값이 50이며 출력값이 1인 fully connected layer\n",
    "        )\n",
    "        \n",
    "    def forward(self, x): #forward 함수를 정의\n",
    "        return self.fc(x) #self.fc의 값을 반환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "846477b3-37df-43a8-874c-f6c903e797c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_model = FCN_seq() #FCN_seq 클래스를 my_model 변수에 할당"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a46397a2-bf43-43cd-9c2c-fb1143009f31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FCN_seq(\n",
       "  (fc): Sequential(\n",
       "    (lin1): Linear(in_features=100, out_features=80, bias=True)\n",
       "    (relu1): ReLU(inplace=True)\n",
       "    (lin2): Linear(in_features=80, out_features=50, bias=True)\n",
       "    (relu2): ReLU(inplace=True)\n",
       "    (lin3): Linear(in_features=50, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_model #모델 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "82dcd525-b541-4f39-8eeb-af74b5d59aee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.0397],\n",
      "        [-0.0058],\n",
      "        [ 0.0512],\n",
      "        [-0.1175],\n",
      "        [ 0.0493],\n",
      "        [-0.0498],\n",
      "        [-0.0433],\n",
      "        [-0.1607],\n",
      "        [-0.0062],\n",
      "        [-0.1179],\n",
      "        [-0.1638],\n",
      "        [-0.0805],\n",
      "        [-0.1165],\n",
      "        [ 0.0313],\n",
      "        [-0.0355],\n",
      "        [-0.1519],\n",
      "        [-0.1232],\n",
      "        [-0.1027],\n",
      "        [-0.1303],\n",
      "        [-0.1960],\n",
      "        [-0.1431],\n",
      "        [-0.1537],\n",
      "        [-0.0523],\n",
      "        [-0.1395],\n",
      "        [-0.1408],\n",
      "        [-0.3325],\n",
      "        [ 0.0091],\n",
      "        [-0.0982],\n",
      "        [-0.0588],\n",
      "        [-0.0658]], grad_fn=<AddmmBackward0>)\n",
      "torch.Size([30, 1])\n"
     ]
    }
   ],
   "source": [
    "print(my_model(X_train)) #결과 확인\n",
    "print(my_model(X_train).shape) #모양 확인"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25fc48cc",
   "metadata": {},
   "source": [
    "## Problem 2\n",
    "\n",
    "problem setup에서 구성한 neural network을 `OrderedDict`을 활용하여 생성하세요\n",
    "- 각 layer의 이름을 주고 생성하세요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50011c60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 답작성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "0b7a32dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FCN_seq(nn.Module): # nn.Module 클래스를 상속받는 FCN_seq라는 클래스를 생성\n",
    "    def __init__(self):       #모델을 정의\n",
    "        super().__init__()     #상위 클래스의 생성자를 호출해 실행\n",
    "        \n",
    "        #self.fc는 nn.Sequential을 사용하여 순차적으로 층을 쌓는 fully connected layer를 정의한다. 이때 ordereddict 기능을 활용해 각 층의 이름을 설정한다.\n",
    "        self.fc = nn.Sequential(OrderedDict([('lin1', nn.Linear(100, 80)),  # 층이름 lin1: 입력값이 100이며 출력값은 80인 fully connected layer\n",
    "                      ('relu1', nn.ReLU(True)), # 층이름 relu1: 액티베이션 함수 렐루를 적용\n",
    "                      ('lin2', nn.Linear(80, 50)), # 층이름 lin2: 입력값이 80이며 출력값은 50인 fully connected layer\n",
    "                      ('relu2',nn.ReLU(True)), # 층이름 relu2: 액티베이션 함수 렐루를 적용\n",
    "                      ('lin3', nn.Linear(50, 1)) # 층이름 lin3: 입력값이 50이며 출력값은 1인 fully connected layer\n",
    "                                            ])\n",
    "        )\n",
    "        \n",
    "    def forward(self, x): #forward 함수를 정의\n",
    "        return self.fc(x) #self.fc의 값을 반환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "e3659cdb-bbb3-4857-89dc-d8c571140a73",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_model = FCN_seq() #FCN_seq 클래스를 my_model 변수에 할당"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "cd6de676-26c3-4721-962b-d64e5fb75afc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FCN_seq(\n",
       "  (fc): Sequential(\n",
       "    (lin1): Linear(in_features=100, out_features=80, bias=True)\n",
       "    (relu1): ReLU(inplace=True)\n",
       "    (lin2): Linear(in_features=80, out_features=50, bias=True)\n",
       "    (relu2): ReLU(inplace=True)\n",
       "    (lin3): Linear(in_features=50, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_model #모델 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "cafd91f5-6f23-4435-91a8-1e03a4ae1236",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0427],\n",
      "        [ 0.0033],\n",
      "        [ 0.0881],\n",
      "        [-0.0857],\n",
      "        [-0.0552],\n",
      "        [-0.0710],\n",
      "        [ 0.0203],\n",
      "        [-0.0425],\n",
      "        [ 0.0599],\n",
      "        [ 0.0232],\n",
      "        [-0.0106],\n",
      "        [-0.0256],\n",
      "        [-0.1325],\n",
      "        [-0.1137],\n",
      "        [ 0.0244],\n",
      "        [-0.2331],\n",
      "        [ 0.0083],\n",
      "        [ 0.0401],\n",
      "        [-0.0459],\n",
      "        [ 0.1170],\n",
      "        [-0.0259],\n",
      "        [ 0.0143],\n",
      "        [ 0.0434],\n",
      "        [-0.0509],\n",
      "        [-0.0328],\n",
      "        [ 0.1981],\n",
      "        [ 0.0574],\n",
      "        [-0.0716],\n",
      "        [-0.0311],\n",
      "        [ 0.1015]], grad_fn=<AddmmBackward0>)\n",
      "torch.Size([30, 1])\n"
     ]
    }
   ],
   "source": [
    "print(my_model(X_train)) #결과 확인\n",
    "print(my_model(X_train).shape) #모양 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be3686fa-5cb9-4065-97f1-cf95c750df72",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "694558b5-22b2-4d5d-8388-8709e9f24968",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d494d942-79c6-4277-ab28-122bb8f7c18e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
